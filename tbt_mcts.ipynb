{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f43e8-237b-4bbe-9dbc-36fb6d30be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "def get_best_known_score(instance: str, problem: str):\n",
    "    file = f\"instances/best_scores_{problem}.txt\"\n",
    "    with open(file, \"r\", encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            instance_, score, optimal = line[:-1].split(\" \")\n",
    "            if instance_ == instance:\n",
    "                return int(score), optimal == \"*\"\n",
    "    raise Exception(f\"instance {instance} not found in {file}\")\n",
    "\n",
    "\n",
    "diff_criteria = [\n",
    "    \"random\",\n",
    "    # \"deleter\",\n",
    "    \"roulette_wheel\",\n",
    "    \"pursuit\",\n",
    "    \"ucb\",\n",
    "    \"neural_net\",\n",
    "]\n",
    "\n",
    "repertory = \"all_methods_all_instances\"\n",
    "\n",
    "problem = \"wvcp\"\n",
    "\n",
    "run_time = 3600 * 2\n",
    "\n",
    "# Choose the set of instances\n",
    "instances_set = (\"pxx\", \"pxx\")\n",
    "instances_set = (\"rxx\", \"rxx\")\n",
    "instances_set = (\"DIMACS_non_optimal\", \"dimacs_no\")\n",
    "instances_set = (\"DIMACS_optimal\", \"dimacs_o\")\n",
    "instances_set = (\"instance_list_wvcp\", \"all\")\n",
    "\n",
    "\n",
    "with open(f\"instances/{instances_set[0]}.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    instances = [line.strip() for line in f.readlines()]\n",
    "\n",
    "title = {\n",
    "    \"iterated\": \"Iterated\",\n",
    "    \"fixed\": \"Random\",\n",
    "    \"random\": \"Random\",\n",
    "    \"deleter\": \"deleter\",\n",
    "    \"roulette_wheel\": \"Roulette wheel\",\n",
    "    \"pursuit\": \"Pursuit\",\n",
    "    \"ucb\": \"UCB\",\n",
    "    \"neural_net\": \"Neural Net\",\n",
    "    \"neural_net_cross\": \"Neural Net Cross\",\n",
    "    \"depth\": \"depth\",\n",
    "    \"depth_fit\": \"depth_fit\",\n",
    "    \"fit\": \"fit\",\n",
    "    \"level\": \"level\",\n",
    "    \"chance\": \"chance\",\n",
    "}\n",
    "\n",
    "colors_min_mean_max = sns.color_palette(\"gray\", 3)\n",
    "\n",
    "# instances = [\"R75_5gb\"]\n",
    "\n",
    "for instance in instances:\n",
    "    # if instance in (\"C2000.5\",\"C2000.9\", \"DSJC125.1gb\"):\n",
    "    #     continue\n",
    "    # if \"DSJC\" in instance:\n",
    "    #     continue\n",
    "    best_score, optimality = get_best_known_score(instance, problem)\n",
    "    for rd in range(2):\n",
    "        fig = plt.figure(tight_layout=True, figsize=(30, 25))\n",
    "        gs = gridspec.GridSpec(int(len(diff_criteria) / 3) + 1, 3)\n",
    "        print(f\"{instance} - randseed {rd}\")\n",
    "\n",
    "        for n_criteria, criteria in enumerate(diff_criteria):\n",
    "\n",
    "            file_best_scores = f\"outputs/{repertory}/{criteria}/{instance}_{rd}.csv\"\n",
    "            if not os.path.exists(file_best_scores):\n",
    "                print(f\"no file {file_best_scores}\")\n",
    "                continue\n",
    "            file_tbt = f\"outputs/{repertory}/{criteria}/tbt/{instance}_{rd}.csv\"\n",
    "            if not os.path.exists(file_tbt):\n",
    "                print(f\"no file {file_tbt}\")\n",
    "                continue\n",
    "\n",
    "            # add score over time\n",
    "            data_score = pd.read_csv(file_best_scores, comment=\"#\")[\n",
    "                [\"score\", \"turn\", \"time\"]\n",
    "            ]\n",
    "            data_score.at[len(data_score) - 1, \"time\"] = run_time\n",
    "\n",
    "            with open(file_tbt, \"r\") as file:\n",
    "                file.readline()\n",
    "                operators = [o for o in file.readline()[1:-1].split(\":\") if o]\n",
    "                # print(operators)\n",
    "            # get the data about turn by turn results\n",
    "            data_tbt = pd.read_csv(file_tbt, comment=\"#\")[\n",
    "                [\n",
    "                    \"time\",\n",
    "                    \"turn\",\n",
    "                    \"proba\",\n",
    "                    \"selected\",\n",
    "                    \"score_pre_ls\",\n",
    "                    \"score_post_ls\",\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "            # operators = data_tbt.local_search[0].split(\":\")\n",
    "            colors = sns.color_palette(\"husl\", len(operators))\n",
    "            count = {m: [0] for m in operators}\n",
    "            scatters_x = [[] for _ in range(len(operators) + 1)]\n",
    "            scatters_y = [[] for _ in range(len(operators) + 1)]\n",
    "            nb_turn = data_score.turn.iloc[-1] + 1\n",
    "            current_turn = -1\n",
    "            for i, (selected, score, score_greedy, turn) in enumerate(\n",
    "                zip(\n",
    "                    data_tbt.selected.to_list(),\n",
    "                    data_tbt.score_post_ls.to_list(),\n",
    "                    data_tbt.score_pre_ls.to_list(),\n",
    "                    data_tbt.turn.to_list(),\n",
    "                )\n",
    "            ):\n",
    "                current_turn += 1\n",
    "                while current_turn != turn:\n",
    "                    current_turn += 1\n",
    "                    for nb_o, o in enumerate(operators):\n",
    "                        if o == \"none\":\n",
    "                            pass\n",
    "                            # count[\"none\"].append(count[\"none\"][-1] + 1)\n",
    "                        else:\n",
    "                            count[o].append(count[o][-1])\n",
    "                for nb_o, o in enumerate(operators):\n",
    "                    if selected == nb_o:\n",
    "                        to_add = 1\n",
    "                        scatters_x[nb_o].append(turn)\n",
    "                        scatters_y[nb_o].append(score)\n",
    "                        scatters_x[-1].append(turn)\n",
    "                        scatters_y[-1].append(score_greedy)\n",
    "                    else:\n",
    "                        to_add = 0\n",
    "                    count[o].append(count[o][-1] + to_add)\n",
    "            # remove first 0\n",
    "            for i, o in enumerate(operators):\n",
    "                count[o].pop(0)\n",
    "\n",
    "            # create the plot\n",
    "\n",
    "            ax = fig.add_subplot(gs[n_criteria // 3, n_criteria % 3])\n",
    "            # for scores\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.plot(data_score.turn, data_score.score, label=\"_score\", color=\"black\")\n",
    "\n",
    "            # print results ls\n",
    "            # x_space = np.linspace(0, nb_turn, nb_turn)\n",
    "            # for o in range(len(operators)):\n",
    "            #     try:\n",
    "            #         # slope, intercept = np.polyfit(scatters_x[o], scatters_y[o], 1)\n",
    "            #         # ax2.plot(slope * x_space + intercept, color=colors[o])\n",
    "            #         ax2.scatter(\n",
    "            #             scatters_x[o], scatters_y[o], label=\"_score\", color=colors[o]\n",
    "            #         )\n",
    "            #     except Exception as e:\n",
    "            #         print(e, o)\n",
    "            #         continue\n",
    "            # if scatters_x[-1]:\n",
    "            #     slope, intercept = np.polyfit(scatters_x[-1], scatters_y[-1], 1)\n",
    "            #     ax2.plot(slope * x_space + intercept, color=\"gray\")\n",
    "            # ax2.scatter(\n",
    "            #     scatters_x[-1], scatters_y[-1], marker=\"x\", label=\"greedy\", color=\"gray\"\n",
    "            # )\n",
    "            ax2.grid(None)\n",
    "            ax2.set_ylim(best_score if optimality else int(best_score * 0.95))\n",
    "\n",
    "            # for selection of operators\n",
    "            for c, o in zip(colors, count.keys()):\n",
    "                ax.plot(count[o], label=o, color=c)\n",
    "\n",
    "            plt.xlim(0, nb_turn)\n",
    "            ax.set_ylim(0)\n",
    "            ax.set_ylabel(\"cumulative selections\")\n",
    "            ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "            color_axis2 = \"gray\"\n",
    "            ax.legend(loc=\"best\")\n",
    "            plt.title(f\"{instance} - {title[criteria]}\")\n",
    "\n",
    "        # plt.savefig(f\"{instance}_rd_{rand_seed}.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f510564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e457203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "def get_best_known_score(instance: str, problem: str):\n",
    "    file = f\"instances/best_scores_{problem}.txt\"\n",
    "    with open(file, \"r\", encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            instance_, score, optimal = line[:-1].split(\" \")\n",
    "            if instance_ == instance:\n",
    "                return int(score), optimal == \"*\"\n",
    "    raise Exception(f\"instance {instance} not found in {file}\")\n",
    "\n",
    "\n",
    "diff_criteria = [\n",
    "    # \"iterated\",\n",
    "    # \"fixed\",\n",
    "    # \"random\",\n",
    "    \"deleter\",\n",
    "    \"roulette_wheel\",\n",
    "    \"pursuit\",\n",
    "    \"ucb\",\n",
    "    \"neural_net\",\n",
    "    # \"depth\",\n",
    "    # \"depth_fit\",\n",
    "    # \"fit\",\n",
    "    # \"level\",\n",
    "    # \"chance\",\n",
    "]\n",
    "\n",
    "repertory = \"mcts_hh_all\"\n",
    "\n",
    "problem = \"wvcp\"\n",
    "\n",
    "run_time = 3600 * 2\n",
    "\n",
    "# Choose the set of instances\n",
    "instances_set = (\"pxx\", \"pxx\")\n",
    "instances_set = (\"rxx\", \"rxx\")\n",
    "instances_set = (\"DIMACS_non_optimal\", \"dimacs_no\")\n",
    "instances_set = (\"DIMACS_optimal\", \"dimacs_o\")\n",
    "instances_set = (\"../instances_hard_wvcp\", \"hard_wvcp\")\n",
    "instances_set = (\"../instances_non_optimal\", \"non_optimal\")\n",
    "instances_set = (\"instance_list_wvcp\", \"all\")\n",
    "instances_set = (\"../DIMACS_hard\", \"dimacs_hard\")\n",
    "\n",
    "\n",
    "with open(f\"instances/{instances_set[0]}.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    instances = [line.strip() for line in f.readlines()]\n",
    "\n",
    "title = {\n",
    "    \"iterated\": \"Iterated\",\n",
    "    \"fixed\": \"Random\",\n",
    "    \"random\": \"Random\",\n",
    "    \"deleter\": \"deleter\",\n",
    "    \"roulette_wheel\": \"Roulette wheel\",\n",
    "    \"pursuit\": \"Pursuit\",\n",
    "    \"ucb\": \"UCB\",\n",
    "    \"q\": \"Q\",\n",
    "    \"neural_net\": \"Neural Net\",\n",
    "    \"neural_net_cross\": \"Neural Net Cross\",\n",
    "    \"depth\": \"depth\",\n",
    "    \"depth_fit\": \"depth_fit\",\n",
    "    \"fit\": \"fit\",\n",
    "    \"level\": \"level\",\n",
    "    \"chance\": \"chance\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_nb_vertices(instance: str):\n",
    "    file = \"instances/instance_info.txt\"\n",
    "    with open(file, \"r\", encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            instance_, nb_vertices, _ = line[:-1].split(\",\")\n",
    "            if instance_ != instance:\n",
    "                continue\n",
    "            return int(nb_vertices)\n",
    "    print(f\"instance {instance} not found in instances/instance_info.txt\")\n",
    "\n",
    "\n",
    "operators = [\"ILSTS\", \"RedLS\", \"TW\", \"AFISA\"]\n",
    "line_styles = [\"-\", \"--\", \"-.\", \":\"]\n",
    "\n",
    "colors = sns.color_palette(\"hls\", len(operators))\n",
    "\n",
    "if not os.path.exists(\"plots\"):\n",
    "    os.mkdir(\"plots\")\n",
    "\n",
    "for instance in instances:\n",
    "    fig = plt.figure(tight_layout=True, figsize=(20, 5))\n",
    "    gs = gridspec.GridSpec(1, 5)\n",
    "    nb_turns = int(3600 / (0.02 * get_nb_vertices(instance)))\n",
    "\n",
    "    for n_criteria, criteria in enumerate(diff_criteria):\n",
    "        # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        mean_curve = {o: [] for o in operators}\n",
    "        for rd in range(20):\n",
    "            file_tbt = f\"outputs/{repertory}/{criteria}/tbt/{instance}_{rd}.csv\"\n",
    "            # get the data about turn by turn results\n",
    "            data_tbt = pd.read_csv(file_tbt, comment=\"#\")[[\"selected\"]]\n",
    "            count = {m: [0] for m in operators}\n",
    "            current_turn = -1\n",
    "            selected_s = data_tbt.selected.to_list()\n",
    "            if nb_turns == -1:\n",
    "                nb_turns = len(selected_s)\n",
    "            elif nb_turns > len(selected_s):\n",
    "                print(\n",
    "                    f\"error {instance} {criteria} nb selected got : {len(selected_s)} before : {nb_turns}\"\n",
    "                )\n",
    "                nb_turns = len(selected_s)\n",
    "                # print(file_tbt)\n",
    "                # continue\n",
    "            # if nb_turns != len(selected_s):\n",
    "            #     print(instance, criteria, rd, len(selected_s), nb)\n",
    "            for selected in selected_s:\n",
    "                for nb_o, o in enumerate(operators):\n",
    "                    if selected == nb_o:\n",
    "                        to_add = 1\n",
    "                    else:\n",
    "                        to_add = 0\n",
    "                    count[o].append(count[o][-1] + to_add)\n",
    "            # remove first 0\n",
    "            for i, o in enumerate(operators):\n",
    "                count[o].pop(0)\n",
    "                mean_curve[o].append(count[o])\n",
    "        x = np.linspace(0, nb_turns, nb_turns)\n",
    "\n",
    "        ax = fig.add_subplot(gs[0, n_criteria % 5])\n",
    "        for i, (o, line_style) in enumerate(zip(operators, line_styles)):\n",
    "            mean_o = np.array(\n",
    "                [np.mean([val[i] for val in mean_curve[o]]) for i in range(nb_turns)]\n",
    "            )\n",
    "            std_o = np.array(\n",
    "                [np.std([val[i] for val in mean_curve[o]]) / 2 for i in range(nb_turns)]\n",
    "            )\n",
    "            ax.fill_between(\n",
    "                x,\n",
    "                mean_o - std_o,\n",
    "                mean_o + std_o,\n",
    "                color=colors[i],\n",
    "                alpha=0.5,\n",
    "            )\n",
    "            ax.plot(x, mean_o, line_style, label=o, color=colors[i])\n",
    "\n",
    "        # handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        # by_label = dict(zip(labels, handles))\n",
    "        # plt.legend(\n",
    "        #     by_label.values(),\n",
    "        #     by_label.keys(),\n",
    "        #     bbox_to_anchor=(1.05, 1),\n",
    "        #     loc=\"upper left\",\n",
    "        #     borderaxespad=0.0,\n",
    "        # )\n",
    "        # plt.grid(True, which=\"both\", linestyle=\"--\")\n",
    "        # print(nb_turns, instance, criteria)\n",
    "        ax.set_xlim(0, nb_turns)\n",
    "        ax.set_ylim(0)\n",
    "        if n_criteria == 0:\n",
    "            plt.legend(loc=\"upper left\")\n",
    "            ax.set_ylabel(\"cumulative selections\")\n",
    "        ax.set_xlabel(\"Iterations\")\n",
    "\n",
    "        plt.title(f\"{instance} - {title[criteria]}\")\n",
    "        nb_selections = {o:0 for o in operators}\n",
    "        for o, v in mean_curve.items():\n",
    "            nb_selections[o] = sum(sum(i) for i in v)\n",
    "        # sort by nb selections\n",
    "        nb_selections = {k: v for k, v in sorted(nb_selections.items(), key=lambda item: item[1])}\n",
    "        print(f\"{instance:20} - {title[criteria]:20} - {nb_selections}\")\n",
    "    plt.savefig(f\"plot_new/{instance}.png\")\n",
    "    # plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce35b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "00275346834db91149e825efe0bdb44b9c59500829b1b6b2a6adcbb27abb4db7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
